---
title: 从零开始的C++机器学习
author: shizuku
tags:
  - 机器学习
  - C++
date: 2020-03-03
location: ChengDu
---

## 前言

这篇文章原是我大一的线代课的作业，后来添了一点东西又成了微积分作业，再后来又添了亿点东西又成了计导作业。现在再修修补补又是一篇博客`o(*￣ ▽ ￣*)ブ`。

假设 $y >= 0$ , 而 $[\log x]$ 表示 $\log x$ 的整数部分, 设:

$$\Phi (y) = \frac {1} {2 \pi i} \int_{2 - i \infty}^{2 + i \infty} \frac {y^{\omega} \mathrm{d} \omega} {\omega \left(1 + \frac {\omega} {(\log x)^{1.1}}\right)^{[ \log x ] + 1}}, x > 1$$

显见， 当 $0 <= y <= 1$ 时， 有 $\Phi(y) = 0$. 对于所有 $y >= 0$, 则 $\Phi(y)$ 是一个非减函数.

当 $\log x>= 10^4$ 及 $y>= e^{2{(\log x)}^{-0.1}}$ 时， 则有:

$$1 - x^{- 0.1} <= \Phi (y) <= 1$$

## 框架

本文我们将只使用 STL 来实现一个最简单的手写数字识别（被誉为深度学习的 Hello world），之所以用简单的例子是因为难的我不会`(～￣ ▽ ￣)～`，或者也可以说是因为简单的例子比较能够看到问题的本质。

那么进入正题，我们首先列出一个框架，然后逢山开路，遇水造桥。我们知道深度学习涉及大量矩阵运算，因此我们首先需要实现一个矩阵类以表示矩阵及其运算。我们知道 python 中的线性代数库 numpy 的矩阵运算底层就是用 c 实现。一种实现是使用模板的，另一种是不使用模板的。两种实现各有利弊，如果使用模板将更符合数学的直觉——矩阵应该是不能随意改变形状的，并且许多行数和列数的匹配问题（比如矩阵乘法的行列匹配关系）可以在编译时发现；而不用模板的话可以更轻松地实现 reshape 的操作，并且可以更方便隐藏源代码。numpy 显然没有使用模板，而我当初写的时候没有考虑这么多，所以写成模板了`(´。＿。｀)`，然后就一直凑合用着。

然后，我们需要读取数据，我们知道深度学习是基于大数据的，没有数据就什么都没有。本文例子所用的数据来自于：http://yann.lecun.com/exdb/mnist/

如果做别的项目，互联网上其实也都有许多数据集可用使用，这就有待于聪明的你去发现了 `o(*￣ ▽ ￣*)ブ`。

有了数据集我们还需要读取，然后做一些处理，因此我们需要实现一个 Reader 类来读取数据。

之后，我们需要构建一个神经网络然后实现预测、训练等功能。

然后就是 main 用来调度。

那么本文以下的内容大概以此为主线展开：

- 实现 la::matrix
- 实现 Reader
- 实现 Framework
- 实现 main

我实现的矩阵类放在名称空间 `la`（linear algebra）中，此外还包含全局的操作符重载和应用于矩阵的函数，而其它几个类并没有塞进名称空间里面，可能稍微有点违和。

## 实现 la::matrix

我们知道 python 中的线性代数库 `numpy` 的矩阵运算底层就是用 C 实现。对于 C++的实现，我们有两种思路，一种实现是使用模板的，另一种是不使用模板的。两种实现各有利弊，如果使用模板将更符合数学的直觉——矩阵应该是不能随意改变形状的，并且许多行数和列数的匹配问题（比如矩阵乘法的行列匹配关系）可以在编译时发现；而不用模板的话可以更轻松地实现 `reshape` 的操作，并且可以更方便隐藏源代码。我所采用的是模板类的方式，在编码风格上模仿了`STL`。

为了方便管理，我们使用一维数组存储数据并提供 `at` 方法访问。为了应对不同的需求，诸如是否下标检查，是否 `const` 访问，提供四种 `at` 方法。为了防止堆栈空间不足而溢出，我们将其动态分配在堆上。
此外还可以提供迭代器以供快速迭代。
实现基本四则运算以及矩阵乘法，实现基本操作如转置，大多以操作符重载的形式实现。
此外还有一些杂乱的功能，例如适用于矩阵的函数，本例用到的其他矩阵操作等。

代码请访问：

## 实现 Reader

根据`mnist`页面的描述，我们编写一个类来读取此数据集。

根据描述，`img`数据的开头为四个 32 位`int`，我们将其读取并忽略。而`lab`数据开头为两个 32 位`int`，同样读取并忽略。如构造函数所示。

`img` 数据为四位表示一个像素点，我们需要连续读取四个位并将其反转，读取这样的 784 个数字并且将其存储在矩阵中，然后返回。`lab` 数据只需要读取一个数字并返回即可。

在`get_img`和`get_lab`函数中用`read`方法读取，`img`数据需要反转，所以添加`private`方法`reverse_32`。

代码请访问：

## 实现 Framework

接下来进行神经网络的实现，我们的神经网络非常简单，只有一个隐藏层，隐藏层也只有十个神经元。对此我们编写一个类实现。类包含 \(b0\)、\(b1\)、\(w1\)三个矩阵。此外还实现了预测`predict`和训练`train`的功能。

在构造函数中我们随机初始化\(w1\)矩阵，随机区间为\([-\sqrt{\frac{6}{28 \times 28 + 10}},\sqrt{\frac{6}{28 \times 28 + 10}}]\)，\(b0\)、\(b1\)则全部为 \(0\)。

预测只需要根据式(5)进行即可。

代码请访问：

训练需要以`train_batch`为单位进行，我们以 100 个数据为一组对神经网络进行调整，总共 600 组。

代码请访问：

以下为类的声明：

代码请访问：

## 实现 main

`main` 模块主要包含 `main` 函数调度和正确率计算功能。

我们在 `main` 函数中实例化神经网络，并进行训练，分别输出训练前和训练后的证确率。代码如下：

代码请访问：

正确率计算并不困难，我们只需要对比期望的结果和实际的结果，并计数即可，代码如下：

代码请访问：

![运行结果](result.png)

如图为实验的结果，最终的正确率大概有 92%，虽然由于神经网络的结构过于简单，致使训练后的正确率并不高，但这样的结果也符合我们的预期。
